{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c0e075",
   "metadata": {},
   "source": [
    "## Content-Based Filtering (Rekomendasi Destinasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9dc618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kota yang tersedia: ['Jakarta' 'Yogyakarta' 'Bandung' 'Semarang' 'Surabaya']\n",
      "\n",
      "Jumlah Data Yogyakarta: 126\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got 'indonesian' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# ## 5. TF-IDF Vectorization\u001b[39;00m\n\u001b[0;32m     37\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindonesian\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_jogja\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcombined_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Hitung similarity\u001b[39;00m\n\u001b[0;32m     41\u001b[0m cosine_sim \u001b[38;5;241m=\u001b[39m cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
      "File \u001b[1;32mc:\\Users\\Rizki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2104\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2098\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2099\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2100\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2101\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2102\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2103\u001b[0m )\n\u001b[1;32m-> 2104\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2106\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rizki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1382\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1377\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1378\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1382\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[0;32m   1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Rizki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:436\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rizki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m     )\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got 'indonesian' instead."
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # TRAVELMATE - Rekomendasi Wisata Yogyakarta\n",
    "# **Teknologi:** Content-Based Filtering\n",
    "# **Dataset:** tourism_with_id.csv\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Persiapan Environment\n",
    "# **Pastikan struktur folder:**\n",
    "# ```\n",
    "# Project/\n",
    "# ├── Datasets/\n",
    "# │   └── tourism_with_id.csv\n",
    "# └── Notebook/\n",
    "#     └── TravelMate_Jogja.ipynb\n",
    "# ```\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Import Library\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Load Data dengan Validasi\n",
    "try:\n",
    "    df = pd.read_csv('../Datasets/tourism_with_id.csv')\n",
    "    print(\"✅ Dataset berhasil dimuat\")\n",
    "    print(f\"Jumlah data: {len(df)}\")\n",
    "    print(f\"Kolom yang tersedia: {list(df.columns)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: File tidak ditemukan. Pastikan:\")\n",
    "    print(\"1. Folder 'Datasets' ada di direktori parent\")\n",
    "    print(\"2. Nama file 'tourism_with_id.csv' benar\")\n",
    "    print(f\"Direktori saat ini: {os.getcwd()}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Filter Data Yogyakarta\n",
    "# Daftar stop words bahasa Indonesia\n",
    "indonesian_stop_words = [\n",
    "    'yang', 'di', 'ke', 'dari', 'dan', 'untuk', 'pada', 'dengan', \n",
    "    'ini', 'itu', 'atau', 'juga', 'dalam', 'tidak', 'akan', 'ada'\n",
    "]\n",
    "\n",
    "# Filter data Jogja\n",
    "if 'City' in df.columns:\n",
    "    df_jogja = df[\n",
    "        df['City'].str.contains('Yogyakarta|DIY', case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    print(\"\\n🔎 Data Yogyakarta:\")\n",
    "    print(f\"Jumlah destinasi: {len(df_jogja)}\")\n",
    "    print(f\"Kategori unik: {df_jogja['Category'].unique()}\")\n",
    "    \n",
    "    # Feature engineering\n",
    "    df_jogja['features'] = (\n",
    "        df_jogja['Place_Name'] + ' ' +\n",
    "        df_jogja['Category'] + ' ' +\n",
    "        df_jogja['Price'].astype(str) + ' ' +\n",
    "        df_jogja['Rating'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # TF-IDF dengan parameter khusus\n",
    "    tfidf = TfidfVectorizer(\n",
    "        stop_words=indonesian_stop_words,\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=500\n",
    "    )\n",
    "    tfidf_matrix = tfidf.fit_transform(df_jogja['features'])\n",
    "    \n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Kolom 'City' tidak ditemukan dalam dataset\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Fungsi Rekomendasi dengan Validasi\n",
    "def rekomendasi_jogja(place_id, n=5):\n",
    "    try:\n",
    "        if place_id not in df_jogja['Place_Id'].values:\n",
    "            return \"⚠️ ID tidak valid\"\n",
    "            \n",
    "        idx = df_jogja[df_jogja['Place_Id'] == place_id].index[0]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:n+1]\n",
    "        \n",
    "        result = df_jogja.iloc[[i[0] for i in sim_scores]][[\n",
    "            'Place_Id', 'Place_Name', 'Category', 'Rating', 'Price'\n",
    "        ]]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"🚨 Error: {str(e)}\"\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Contoh Penggunaan\n",
    "if not df_jogja.empty:\n",
    "    sample_id = df_jogja['Place_Id'].iloc[0]\n",
    "    print(f\"\\nContoh rekomendasi untuk ID {sample_id}:\")\n",
    "    print(rekomendasi_jogja(sample_id))\n",
    "else:\n",
    "    print(\"\\nTidak ada data Yogyakarta yang tersedia\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Simpan Model\n",
    "if not df_jogja.empty:\n",
    "    joblib.dump(\n",
    "        {\n",
    "            'tfidf': tfidf,\n",
    "            'cosine_sim': cosine_sim,\n",
    "            'metadata': df_jogja[['Place_Id', 'Place_Name']]\n",
    "        },\n",
    "        'travelmate_jogja_model.joblib'\n",
    "    )\n",
    "    print(\"\\n💾 Model berhasil disimpan\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
